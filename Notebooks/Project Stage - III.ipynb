{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Stage - III (Basic Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "The goal of Stage II is to utlize machine learning and statistical models to predict the trend of COVID-19 cases / deaths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "\n",
    "#### Task 1: (70 pts)\n",
    "- Team: (30)\n",
    "    - Develop Linear and Non-Linear (polynomial) regression models for predicting cases and deaths in US. \n",
    "        - Start your data from the first day of infections in US. X-Axis - number of days since the first case, Y-Axis - number of new cases and deaths.\n",
    "        - Calculate and report Root Mean Square Error (RMSE) for your models (linear and non-linear). Discuss bias versus variance tradeoff.\n",
    "        - Plot trend line along for the data along with the forecast of 1 week ahead. \n",
    "        - Describe the trends as compared to other countries. \n",
    "- Member: (40 pts)\n",
    "    - Utilize Linear and Non-Linear (polynomial) regression models to compare trends for a single state and its counties (top 5 with highest number of cases). Start your data from the first day of infections. \n",
    "        - X-Axis - number of days since the first case, Y - Axis number of new cases and deaths. Calcluate error using RMSE.\n",
    "        - Identify which counties are most at risk. Model for top 5 counties with cases within a state and describe their trends.\n",
    "        - Utilize the hospital data to calculate the point of no return for a state. Use percentage occupancy / utilization to see which states are close and what their trend looks like.\n",
    "     - Perform hypothesis tests on questions identified in Stage II\n",
    "        - e.x. *Does higher employment data (overall employment numbers) lead to higher covid case numbers or more rapid increase in covid cases.*. Here you would compare the covid cases to the state or county level enrichment data to prove or disprove your null hypothesis. In this case there will be a two tail - two sample t-test to see if there is a difference and then one-tail - two sample t-test to show higher or lower.\n",
    "        - Depending on your type of data you can also perform Chi-square test for categorical hypothesis testing. \n",
    "\n",
    "    \n",
    "#### Task 2: (30 pts)\n",
    "- Member:\n",
    "    - For each of the aforemention analysis plot graphs,\n",
    "        - trend line\n",
    "        - confidence intervals (error in prediction)\n",
    "        - prediction path (forecast)\n",
    "\n",
    "**Deliverable**\n",
    "- Each member creates separate notebooks for member tasks. Upload all notebooks and reports to Github Repository. \n",
    "- Presentation recordings on canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadline: 11/18/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"D:/Kiptaror/CSC-405-605_Fall_2021-master/data/owid-covid-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>female_smokers</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133494</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>133329.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.000</td>\n",
       "      <td>4694.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.286</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>30.7</td>\n",
       "      <td>36.791</td>\n",
       "      <td>1.7</td>\n",
       "      <td>61.49</td>\n",
       "      <td>0.571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133495</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>133329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.000</td>\n",
       "      <td>4694.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.286</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>30.7</td>\n",
       "      <td>36.791</td>\n",
       "      <td>1.7</td>\n",
       "      <td>61.49</td>\n",
       "      <td>0.571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133496</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2021-11-13</td>\n",
       "      <td>133393.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.143</td>\n",
       "      <td>4696.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.571</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>30.7</td>\n",
       "      <td>36.791</td>\n",
       "      <td>1.7</td>\n",
       "      <td>61.49</td>\n",
       "      <td>0.571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133497</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2021-11-14</td>\n",
       "      <td>133428.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>34.429</td>\n",
       "      <td>4696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.571</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>30.7</td>\n",
       "      <td>36.791</td>\n",
       "      <td>1.7</td>\n",
       "      <td>61.49</td>\n",
       "      <td>0.571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133498</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>133438.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.286</td>\n",
       "      <td>4697.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>30.7</td>\n",
       "      <td>36.791</td>\n",
       "      <td>1.7</td>\n",
       "      <td>61.49</td>\n",
       "      <td>0.571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133499 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       iso_code continent     location        date  total_cases  new_cases  \\\n",
       "0           AFG      Asia  Afghanistan  2020-02-24          5.0        5.0   \n",
       "1           AFG      Asia  Afghanistan  2020-02-25          5.0        0.0   \n",
       "2           AFG      Asia  Afghanistan  2020-02-26          5.0        0.0   \n",
       "3           AFG      Asia  Afghanistan  2020-02-27          5.0        0.0   \n",
       "4           AFG      Asia  Afghanistan  2020-02-28          5.0        0.0   \n",
       "...         ...       ...          ...         ...          ...        ...   \n",
       "133494      ZWE    Africa     Zimbabwe  2021-11-11     133329.0       27.0   \n",
       "133495      ZWE    Africa     Zimbabwe  2021-11-12     133329.0        0.0   \n",
       "133496      ZWE    Africa     Zimbabwe  2021-11-13     133393.0       64.0   \n",
       "133497      ZWE    Africa     Zimbabwe  2021-11-14     133428.0       35.0   \n",
       "133498      ZWE    Africa     Zimbabwe  2021-11-15     133438.0       10.0   \n",
       "\n",
       "        new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  \\\n",
       "0                      NaN           NaN         NaN                  NaN   \n",
       "1                      NaN           NaN         NaN                  NaN   \n",
       "2                      NaN           NaN         NaN                  NaN   \n",
       "3                      NaN           NaN         NaN                  NaN   \n",
       "4                      NaN           NaN         NaN                  NaN   \n",
       "...                    ...           ...         ...                  ...   \n",
       "133494              31.000        4694.0         0.0                1.286   \n",
       "133495              31.000        4694.0         0.0                1.286   \n",
       "133496              32.143        4696.0         2.0                1.571   \n",
       "133497              34.429        4696.0         0.0                1.571   \n",
       "133498              33.286        4697.0         1.0                1.000   \n",
       "\n",
       "        ...  female_smokers  male_smokers  handwashing_facilities  \\\n",
       "0       ...             NaN           NaN                  37.746   \n",
       "1       ...             NaN           NaN                  37.746   \n",
       "2       ...             NaN           NaN                  37.746   \n",
       "3       ...             NaN           NaN                  37.746   \n",
       "4       ...             NaN           NaN                  37.746   \n",
       "...     ...             ...           ...                     ...   \n",
       "133494  ...             1.6          30.7                  36.791   \n",
       "133495  ...             1.6          30.7                  36.791   \n",
       "133496  ...             1.6          30.7                  36.791   \n",
       "133497  ...             1.6          30.7                  36.791   \n",
       "133498  ...             1.6          30.7                  36.791   \n",
       "\n",
       "        hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
       "0                              0.5            64.83                    0.511   \n",
       "1                              0.5            64.83                    0.511   \n",
       "2                              0.5            64.83                    0.511   \n",
       "3                              0.5            64.83                    0.511   \n",
       "4                              0.5            64.83                    0.511   \n",
       "...                            ...              ...                      ...   \n",
       "133494                         1.7            61.49                    0.571   \n",
       "133495                         1.7            61.49                    0.571   \n",
       "133496                         1.7            61.49                    0.571   \n",
       "133497                         1.7            61.49                    0.571   \n",
       "133498                         1.7            61.49                    0.571   \n",
       "\n",
       "        excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                        NaN                          NaN   \n",
       "1                                        NaN                          NaN   \n",
       "2                                        NaN                          NaN   \n",
       "3                                        NaN                          NaN   \n",
       "4                                        NaN                          NaN   \n",
       "...                                      ...                          ...   \n",
       "133494                                   NaN                          NaN   \n",
       "133495                                   NaN                          NaN   \n",
       "133496                                   NaN                          NaN   \n",
       "133497                                   NaN                          NaN   \n",
       "133498                                   NaN                          NaN   \n",
       "\n",
       "        excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0                    NaN                                      NaN  \n",
       "1                    NaN                                      NaN  \n",
       "2                    NaN                                      NaN  \n",
       "3                    NaN                                      NaN  \n",
       "4                    NaN                                      NaN  \n",
       "...                  ...                                      ...  \n",
       "133494               NaN                                      NaN  \n",
       "133495               NaN                                      NaN  \n",
       "133496               NaN                                      NaN  \n",
       "133497               NaN                                      NaN  \n",
       "133498               NaN                                      NaN  \n",
       "\n",
       "[133499 rows x 67 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_calculation(df_all,state,date,day):\n",
    "    df_country = df_all.copy()\n",
    "    df_country = df_country.loc[df_country['date'] >= date]\n",
    "    df_country = df_country.loc[df_country['state'] == country_dict[country]]\n",
    "    features = ['iso_code', 'continent', 'location','total_cases', 'total_deaths', 'date']\n",
    "    df_country = df_country[features]\n",
    "    \n",
    "    # Lags\n",
    "    df_country = lag_feature(df_country, 'total_cases',range(1, 40))\n",
    "    df_country = lag_feature(df_country, 'total_deaths', range(1,20))\n",
    "\n",
    "    filter_col_confirmed = [col for col in df_country if col.startswith('total_cases')]\n",
    "    filter_col_fatalities= [col for col in df_country if col.startswith('death')]\n",
    "    filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n",
    "    \n",
    "    # Apply log transformation\n",
    "    df_country[filter_col] = df_country[filter_col].apply(lambda x: np.log1p(x))\n",
    "    df_country.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df_country.fillna(0, inplace=True) ####\n",
    "    \n",
    "    # Start/end of forecast\n",
    "    start = df_country[df_country['iso_code']==-999].Day_num.min()\n",
    "    end = df_country[df_country['iso_code']==-999].Day_num.max()\n",
    "    #\n",
    "    for d in range(start,end+1):\n",
    "   \n",
    "        X_train_1, X_train_2, Y_train_1, Y_train_2, x_test_1, x_test_2 = train_test_split_extend(df_country,d,day,filter_col_confirmed,filter_col_fatalities)\n",
    "        \n",
    "        regr_1, pred_1 = lin_reg(X_train_1, Y_train_1, x_test_1)\n",
    "        df_country.loc[(df_country['Day_num'] == d) & (df_country['state'] == country_dict[country]), 'total_cases'] = pred_1[0]\n",
    "        \n",
    "        regr_2, pred_2 = lin_reg(X_train_2, Y_train_2, x_test_2)\n",
    "        df_country.loc[(df_country['Day_num'] == d) & (df_country['Country'] == country_dict[country]), 'death'] = pred_2[0]\n",
    "        \n",
    "        df_country = lag_feature(df_country, 'total_cases',range(1, 40))\n",
    "        df_country = lag_feature(df_country, 'death', range(1,20))\n",
    "\n",
    "        df_country.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        df_country.fillna(0, inplace=True)\n",
    "        \n",
    "    print(\"Calculation done.\")\n",
    "    return df_country\n",
    "    \n",
    "    df_check = country_calculation(df_all, 'Germany', '2020-03-10', 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 133499 entries, 0 to 133498\n",
      "Data columns (total 67 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   iso_code                                    133499 non-null  object \n",
      " 1   continent                                   124973 non-null  object \n",
      " 2   location                                    133499 non-null  object \n",
      " 3   date                                        133499 non-null  object \n",
      " 4   total_cases                                 126238 non-null  float64\n",
      " 5   new_cases                                   126236 non-null  float64\n",
      " 6   new_cases_smoothed                          125193 non-null  float64\n",
      " 7   total_deaths                                115089 non-null  float64\n",
      " 8   new_deaths                                  115285 non-null  float64\n",
      " 9   new_deaths_smoothed                         125193 non-null  float64\n",
      " 10  total_cases_per_million                     125590 non-null  float64\n",
      " 11  new_cases_per_million                       125588 non-null  float64\n",
      " 12  new_cases_smoothed_per_million              124550 non-null  float64\n",
      " 13  total_deaths_per_million                    114454 non-null  float64\n",
      " 14  new_deaths_per_million                      114650 non-null  float64\n",
      " 15  new_deaths_smoothed_per_million             124550 non-null  float64\n",
      " 16  reproduction_rate                           104981 non-null  float64\n",
      " 17  icu_patients                                15978 non-null   float64\n",
      " 18  icu_patients_per_million                    15978 non-null   float64\n",
      " 19  hosp_patients                               18719 non-null   float64\n",
      " 20  hosp_patients_per_million                   18719 non-null   float64\n",
      " 21  weekly_icu_admissions                       1341 non-null    float64\n",
      " 22  weekly_icu_admissions_per_million           1341 non-null    float64\n",
      " 23  weekly_hosp_admissions                      2130 non-null    float64\n",
      " 24  weekly_hosp_admissions_per_million          2130 non-null    float64\n",
      " 25  new_tests                                   55661 non-null   float64\n",
      " 26  total_tests                                 55985 non-null   float64\n",
      " 27  total_tests_per_thousand                    55985 non-null   float64\n",
      " 28  new_tests_per_thousand                      55661 non-null   float64\n",
      " 29  new_tests_smoothed                          67745 non-null   float64\n",
      " 30  new_tests_smoothed_per_thousand             67745 non-null   float64\n",
      " 31  positive_rate                               63236 non-null   float64\n",
      " 32  tests_per_case                              62576 non-null   float64\n",
      " 33  tests_units                                 69763 non-null   object \n",
      " 34  total_vaccinations                          33673 non-null   float64\n",
      " 35  people_vaccinated                           32108 non-null   float64\n",
      " 36  people_fully_vaccinated                     29130 non-null   float64\n",
      " 37  total_boosters                              6038 non-null    float64\n",
      " 38  new_vaccinations                            28033 non-null   float64\n",
      " 39  new_vaccinations_smoothed                   59881 non-null   float64\n",
      " 40  total_vaccinations_per_hundred              33673 non-null   float64\n",
      " 41  people_vaccinated_per_hundred               32108 non-null   float64\n",
      " 42  people_fully_vaccinated_per_hundred         29130 non-null   float64\n",
      " 43  total_boosters_per_hundred                  6038 non-null    float64\n",
      " 44  new_vaccinations_smoothed_per_million       59881 non-null   float64\n",
      " 45  new_people_vaccinated_smoothed              58645 non-null   float64\n",
      " 46  new_people_vaccinated_smoothed_per_hundred  58645 non-null   float64\n",
      " 47  stringency_index                            108855 non-null  float64\n",
      " 48  population                                  132548 non-null  float64\n",
      " 49  population_density                          120851 non-null  float64\n",
      " 50  median_age                                  115168 non-null  float64\n",
      " 51  aged_65_older                               113894 non-null  float64\n",
      " 52  aged_70_older                               114539 non-null  float64\n",
      " 53  gdp_per_capita                              115923 non-null  float64\n",
      " 54  extreme_poverty                             77521 non-null   float64\n",
      " 55  cardiovasc_death_rate                       115417 non-null  float64\n",
      " 56  diabetes_prevalence                         119188 non-null  float64\n",
      " 57  female_smokers                              89913 non-null   float64\n",
      " 58  male_smokers                                88613 non-null   float64\n",
      " 59  handwashing_facilities                      58093 non-null   float64\n",
      " 60  hospital_beds_per_thousand                  104888 non-null  float64\n",
      " 61  life_expectancy                             124109 non-null  float64\n",
      " 62  human_development_index                     115527 non-null  float64\n",
      " 63  excess_mortality_cumulative_absolute        4656 non-null    float64\n",
      " 64  excess_mortality_cumulative                 4656 non-null    float64\n",
      " 65  excess_mortality                            4656 non-null    float64\n",
      " 66  excess_mortality_cumulative_per_million     4656 non-null    float64\n",
      "dtypes: float64(62), object(5)\n",
      "memory usage: 68.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_calculation(df_all,state,date,day):\n",
    "    df_country = df_all.copy()\n",
    "    df_country = df_country.loc[df_country['date'] >= date]\n",
    "    df_country = df_country.loc[df_country['state'] == country_dict[country]]\n",
    "    features = ['Id', 'State', 'location','ConfirmedCases', 'deaths', 'Day_num']\n",
    "    df_country = df_country[features]\n",
    "    \n",
    "    # Lags\n",
    "    df_country = lag_feature(df_country, 'ConfirmedCases',range(1, 40))\n",
    "    df_country = lag_feature(df_country, 'deaths', range(1,20))\n",
    "\n",
    "    filter_col_confirmed = [col for col in df_country if col.startswith('Confirmed')]\n",
    "    filter_col_fatalities= [col for col in df_country if col.startswith('deaths')]\n",
    "    filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n",
    "    \n",
    "    # Apply log transformation\n",
    "    df_country[filter_col] = df_country[filter_col].apply(lambda x: np.log1p(x))\n",
    "    df_country.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df_country.fillna(0, inplace=True) ####\n",
    "    \n",
    "    # Start/end of forecast\n",
    "    start = df_country[df_country['iso_code']==-999].Day_num.min()\n",
    "    end = df_country[df_country['iso_code']==-999].Day_num.max()\n",
    "    #\n",
    "    for d in range(start,end+1):\n",
    "   \n",
    "        X_train_1, X_train_2, Y_train_1, Y_train_2, x_test_1, x_test_2 = train_test_split_extend(df_country,d,day,filter_col_confirmed,filter_col_fatalities)\n",
    "        \n",
    "        regr_1, pred_1 = lin_reg(X_train_1, Y_train_1, x_test_1)\n",
    "        df_country.loc[(df_country['Day_num'] == d) & (df_country['state'] == country_dict[country]), 'ConfirmedCases'] = pred_1[0]\n",
    "        \n",
    "        regr_2, pred_2 = lin_reg(X_train_2, Y_train_2, x_test_2)\n",
    "        df_country.loc[(df_country['Day_num'] == d) & (df_country['state'] == country_dict[country]), 'deaths'] = pred_2[0]\n",
    "        \n",
    "        df_country = lag_feature(df_country, 'ConfirmedCases',range(1, 40))\n",
    "        df_country = lag_feature(df_country, 'deaths', range(1,20))\n",
    "\n",
    "        df_country.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        df_country.fillna(0, inplace=True)\n",
    "        \n",
    "    print(\"Calculation done.\")\n",
    "    return df_country\n",
    "    \n",
    "    df_check = country_calculation(df_all, 'Germany', '2020-03-10', 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining key dates for reference purposes #\n",
    "feature_day = [1,20,50,100,200,500,1000]\n",
    "def CreateInput(data):\n",
    "    feature = []\n",
    "    for day in feature_day:\n",
    "        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n",
    "        if (train[(train['continent'] == country) & (train['location'] == province) & (train['ConfirmedCases'] < day)]['date'].count() > 0):\n",
    "            fromday = train[(train['continent'] == country) & (train['location'] == province) & (train['ConfirmedCases'] < day)]['date'].max()        \n",
    "        else:\n",
    "            fromday = train[(train['continent'] == country) & (train['location'] == province)]['date'].min()       \n",
    "        for i in range(0, len(data)):\n",
    "            if (data['date'].iloc[i] > fromday):\n",
    "                day_denta = data['date'].iloc[i] - fromday\n",
    "                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n",
    "        feature = feature + ['Number day from ' + str(day) + ' case']\n",
    "    \n",
    "    return data[feature]\n",
    "    \n",
    "pred_data_all = pd.DataFrame()\n",
    "for country in train['continent'].unique():\n",
    "    for province in train[(train['continent'] == country)]['location'].unique():\n",
    "        print(country + ' and ' + province)\n",
    "        #create dataframe for a specific country\n",
    "        df_train = train[(train['continent'] == country) & (train['location'] == province)]\n",
    "        df_test = test[(test['continent'] == country) & (test['location'] == province)]\n",
    "        #create features -> number of cases on a specific date\n",
    "        X_train = CreateInput(df_train)\n",
    "        #last 12 confirmed cases in train data set\n",
    "        y_train_confirmed = df_train['ConfirmedCases'].ravel()\n",
    "        #last 12 confirmed fatalities in train data set\n",
    "        y_train_fatalities = df_train['death'].ravel()\n",
    "        #create features in test dataset-> number of cases on a specific date\n",
    "        X_pred = CreateInput(df_test)\n",
    "        #creates reversed list of the possible features\n",
    "        for day in sorted(feature_day,reverse = True):\n",
    "            #check for the column in the list\n",
    "            feature_use = 'Number day from ' + str(day) + ' case'\n",
    "            #check the 0-dimension of the array (similiar to length of a dataframe)\n",
    "            idx = X_train[X_train[feature_use] == 0].shape[0]     \n",
    "            #if there are more than 20 values for a column, the loop will be interruped\n",
    "            if (X_train[X_train[feature_use] > 0].shape[0] >= 20):\n",
    "                break\n",
    "                \n",
    "        #[TRAIN] - cuts the value of idx from the top of the dataframe; selects the input column (e.g. Number day from 1000 case); brings it into a horizontal array\n",
    "        adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n",
    "        #[TRAIN] - get the respective confirmed cases\n",
    "        adjusted_y_train_confirmed = y_train_confirmed[idx:]\n",
    "        #[TRAIN] - get the respective fatalities\n",
    "        adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n",
    "        \n",
    "        #[TEST] - selects for the extracted feature column and get the length (0)\n",
    "        idx = X_pred[X_pred[feature_use] == 0].shape[0]\n",
    "        \n",
    "        #[TEST] - creates a clean array also for the prediction\n",
    "        adjusted_X_pred = X_pred[idx:][feature_use].values.reshape(-1, 1)\n",
    "        \n",
    "        #[TEST] - gets the extract from the test dataset for a specific country/ region\n",
    "        pred_data = test[(test['continent'] == country) & (test['location'] == province)]\n",
    "        \n",
    "        #latest date from the trainings data set and earliest date from the test data set\n",
    "        max_train_date = train[(train['continent'] == country) & (train['location'] == province)]['Date'].max()\n",
    "        min_test_date = pred_data['date'].min()\n",
    "        \n",
    "        if len(adjusted_y_train_confirmed) < 1:\n",
    "            adjusted_y_train_confirmed = np.zeros(3)\n",
    "        else:\n",
    "            if len(adjusted_y_train_confirmed) < 2:\n",
    "                adjusted_y_train_confirmed = np.append(adjusted_y_train_confirmed,adjusted_y_train_confirmed[len(adjusted_y_train_confirmed)-1],adjusted_y_train_confirmed[len(adjusted_y_train_confirmed)-1])\n",
    "            else:\n",
    "                if len(adjusted_y_train_confirmed) < 3:\n",
    "                    adjusted_y_train_confirmed = np.append(adjusted_y_train_confirmed,adjusted_y_train_confirmed[len(adjusted_y_train_confirmed)-1])\n",
    "                else:\n",
    "                    pass\n",
    "        \n",
    "        #[CONFIRMED CASES] - prediction and modelling\n",
    "        model = SARIMAX(adjusted_y_train_confirmed, order=(1,1,0), \n",
    "                        measurement_error=True).fit(disp=False)\n",
    "        y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n",
    "        y_train_confirmed = train[(train['continent'] == country) & (train['location'] == province) & (train['date'] >=  min_test_date)]['ConfirmedCases'].values\n",
    "        y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)\n",
    "\n",
    "        if len(adjusted_y_train_fatalities) < 1:\n",
    "            adjusted_y_train_fatalities = np.zeros(3)\n",
    "        else:\n",
    "            if len(adjusted_y_train_fatalities) < 2:\n",
    "                adjusted_y_train_fatalities = np.append(adjusted_y_train_fatalities,adjusted_y_train_fatalities[len(adjusted_y_train_fatalities)-1],adjusted_y_train_fatalities[len(adjusted_y_train_fatalities)-1])\n",
    "            else:\n",
    "                if len(adjusted_y_train_fatalities) < 3:\n",
    "                    adjusted_y_train_fatalities = np.append(adjusted_y_train_fatalities,adjusted_y_train_fatalities[len(adjusted_y_train_fatalities)-1])\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "        #[FATALITIES] - prediction and modelling\n",
    "        model = SARIMAX(adjusted_y_train_fatalities, order=(1,1,0), \n",
    "                        measurement_error=True).fit(disp=False)\n",
    "        y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n",
    "        y_train_fatalities = train[(train['continent'] == country) & (train['location'] == province) & (train['date'] >=  min_test_date)]['Fatalities'].values\n",
    "        y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)\n",
    "        pred_data['ConfirmedCases_hat'] =  y_hat_confirmed\n",
    "        pred_data['Fatalities_hat'] = y_hat_fatalities\n",
    "        pred_data_all = pred_data_all.append(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
