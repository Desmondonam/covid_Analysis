{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Stage - III (Basic Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "The goal of Stage II is to utlize machine learning and statistical models to predict the trend of COVID-19 cases / deaths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "\n",
    "#### Task 1: (70 pts)\n",
    "- Team: (30)\n",
    "    - Develop Linear and Non-Linear (polynomial) regression models for predicting cases and deaths in US. \n",
    "        - Start your data from the first day of infections in US. X-Axis - number of days since the first case, Y-Axis - number of new cases and deaths.\n",
    "        - Calculate and report Root Mean Square Error (RMSE) for your models (linear and non-linear). Discuss bias versus variance tradeoff.\n",
    "        - Plot trend line along for the data along with the forecast of 1 week ahead. \n",
    "        - Describe the trends as compared to other countries. \n",
    "- Member: (40 pts)\n",
    "    - Utilize Linear and Non-Linear (polynomial) regression models to compare trends for a single state and its counties (top 5 with highest number of cases). Start your data from the first day of infections. \n",
    "        - X-Axis - number of days since the first case, Y - Axis number of new cases and deaths. Calcluate error using RMSE.\n",
    "        - Identify which counties are most at risk. Model for top 5 counties with cases within a state and describe their trends.\n",
    "        - Utilize the hospital data to calculate the point of no return for a state. Use percentage occupancy / utilization to see which states are close and what their trend looks like.\n",
    "     - Perform hypothesis tests on questions identified in Stage II\n",
    "        - e.x. *Does higher employment data (overall employment numbers) lead to higher covid case numbers or more rapid increase in covid cases.*. Here you would compare the covid cases to the state or county level enrichment data to prove or disprove your null hypothesis. In this case there will be a two tail - two sample t-test to see if there is a difference and then one-tail - two sample t-test to show higher or lower.\n",
    "        - Depending on your type of data you can also perform Chi-square test for categorical hypothesis testing. \n",
    "\n",
    "    \n",
    "#### Task 2: (30 pts)\n",
    "- Member:\n",
    "    - For each of the aforemention analysis plot graphs,\n",
    "        - trend line\n",
    "        - confidence intervals (error in prediction)\n",
    "        - prediction path (forecast)\n",
    "\n",
    "**Deliverable**\n",
    "- Each member creates separate notebooks for member tasks. Upload all notebooks and reports to Github Repository. \n",
    "- Presentation recordings on canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadline: 11/18/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_calculation(df_all,country,date,day):\n",
    "    df_country = df_all.copy()\n",
    "    df_country = df_country.loc[df_country['Date'] >= date]\n",
    "    df_country = df_country.loc[df_country['Country'] == country_dict[country]]\n",
    "    features = ['iso_code', 'continent', 'location','total_cases', 'total_deaths', 'date']\n",
    "    df_country = df_country[features]\n",
    "    \n",
    "    # Lags\n",
    "    df_country = lag_feature(df_country, 'total_cases',range(1, 40))\n",
    "    df_country = lag_feature(df_country, 'total_deaths', range(1,20))\n",
    "\n",
    "    filter_col_confirmed = [col for col in df_country if col.startswith('total_cases')]\n",
    "    filter_col_fatalities= [col for col in df_country if col.startswith('Fataliti')]\n",
    "    filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n",
    "    \n",
    "    # Apply log transformation\n",
    "    df_country[filter_col] = df_country[filter_col].apply(lambda x: np.log1p(x))\n",
    "    df_country.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df_country.fillna(0, inplace=True) ####\n",
    "    \n",
    "    # Start/end of forecast\n",
    "    start = df_country[df_country['Id']==-999].Day_num.min()\n",
    "    end = df_country[df_country['Id']==-999].Day_num.max()\n",
    "    #\n",
    "    for d in range(start,end+1):\n",
    "   \n",
    "        X_train_1, X_train_2, Y_train_1, Y_train_2, x_test_1, x_test_2 = train_test_split_extend(df_country,d,day,filter_col_confirmed,filter_col_fatalities)\n",
    "        \n",
    "        regr_1, pred_1 = lin_reg(X_train_1, Y_train_1, x_test_1)\n",
    "        df_country.loc[(df_country['Day_num'] == d) & (df_country['Country'] == country_dict[country]), 'total_cases'] = pred_1[0]\n",
    "        \n",
    "        regr_2, pred_2 = lin_reg(X_train_2, Y_train_2, x_test_2)\n",
    "        df_country.loc[(df_country['Day_num'] == d) & (df_country['Country'] == country_dict[country]), 'Fatalities'] = pred_2[0]\n",
    "        \n",
    "        df_country = lag_feature(df_country, 'total_cases',range(1, 40))\n",
    "        df_country = lag_feature(df_country, 'Fatalities', range(1,20))\n",
    "\n",
    "        df_country.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        df_country.fillna(0, inplace=True)\n",
    "        \n",
    "    print(\"Calculation done.\")\n",
    "    return df_country\n",
    "    \n",
    "    df_check = country_calculation(df_all, 'Germany', '2020-03-10', 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_calculation(df_all,country,date,day):\n",
    "    df_country = df_all.copy()\n",
    "    df_country = df_country.loc[df_country['Date'] >= date]\n",
    "    df_country = df_country.loc[df_country['Country'] == country_dict[country]]\n",
    "    features = ['Id', 'State', 'Country','ConfirmedCases', 'Fatalities', 'Day_num']\n",
    "    df_country = df_country[features]\n",
    "    \n",
    "    # Lags\n",
    "    df_country = lag_feature(df_country, 'ConfirmedCases',range(1, 40))\n",
    "    df_country = lag_feature(df_country, 'Fatalities', range(1,20))\n",
    "\n",
    "    filter_col_confirmed = [col for col in df_country if col.startswith('Confirmed')]\n",
    "    filter_col_fatalities= [col for col in df_country if col.startswith('Fataliti')]\n",
    "    filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n",
    "    \n",
    "    # Apply log transformation\n",
    "    df_country[filter_col] = df_country[filter_col].apply(lambda x: np.log1p(x))\n",
    "    df_country.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df_country.fillna(0, inplace=True) ####\n",
    "    \n",
    "    # Start/end of forecast\n",
    "    start = df_country[df_country['Id']==-999].Day_num.min()\n",
    "    end = df_country[df_country['Id']==-999].Day_num.max()\n",
    "    #\n",
    "    for d in range(start,end+1):\n",
    "   \n",
    "        X_train_1, X_train_2, Y_train_1, Y_train_2, x_test_1, x_test_2 = train_test_split_extend(df_country,d,day,filter_col_confirmed,filter_col_fatalities)\n",
    "        \n",
    "        regr_1, pred_1 = lin_reg(X_train_1, Y_train_1, x_test_1)\n",
    "        df_country.loc[(df_country['Day_num'] == d) & (df_country['Country'] == country_dict[country]), 'ConfirmedCases'] = pred_1[0]\n",
    "        \n",
    "        regr_2, pred_2 = lin_reg(X_train_2, Y_train_2, x_test_2)\n",
    "        df_country.loc[(df_country['Day_num'] == d) & (df_country['Country'] == country_dict[country]), 'Fatalities'] = pred_2[0]\n",
    "        \n",
    "        df_country = lag_feature(df_country, 'ConfirmedCases',range(1, 40))\n",
    "        df_country = lag_feature(df_country, 'Fatalities', range(1,20))\n",
    "\n",
    "        df_country.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        df_country.fillna(0, inplace=True)\n",
    "        \n",
    "    print(\"Calculation done.\")\n",
    "    return df_country\n",
    "    \n",
    "    df_check = country_calculation(df_all, 'Germany', '2020-03-10', 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining key dates for reference purposes #\n",
    "feature_day = [1,20,50,100,200,500,1000]\n",
    "def CreateInput(data):\n",
    "    feature = []\n",
    "    for day in feature_day:\n",
    "        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n",
    "        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n",
    "            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n",
    "        else:\n",
    "            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n",
    "        for i in range(0, len(data)):\n",
    "            if (data['Date'].iloc[i] > fromday):\n",
    "                day_denta = data['Date'].iloc[i] - fromday\n",
    "                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n",
    "        feature = feature + ['Number day from ' + str(day) + ' case']\n",
    "    \n",
    "    return data[feature]\n",
    "    \n",
    "pred_data_all = pd.DataFrame()\n",
    "for country in train['Country_Region'].unique():\n",
    "    for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n",
    "        print(country + ' and ' + province)\n",
    "        #create dataframe for a specific country\n",
    "        df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n",
    "        df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n",
    "        #create features -> number of cases on a specific date\n",
    "        X_train = CreateInput(df_train)\n",
    "        #last 12 confirmed cases in train data set\n",
    "        y_train_confirmed = df_train['ConfirmedCases'].ravel()\n",
    "        #last 12 confirmed fatalities in train data set\n",
    "        y_train_fatalities = df_train['Fatalities'].ravel()\n",
    "        #create features in test dataset-> number of cases on a specific date\n",
    "        X_pred = CreateInput(df_test)\n",
    "        #creates reversed list of the possible features\n",
    "        for day in sorted(feature_day,reverse = True):\n",
    "            #check for the column in the list\n",
    "            feature_use = 'Number day from ' + str(day) + ' case'\n",
    "            #check the 0-dimension of the array (similiar to length of a dataframe)\n",
    "            idx = X_train[X_train[feature_use] == 0].shape[0]     \n",
    "            #if there are more than 20 values for a column, the loop will be interruped\n",
    "            if (X_train[X_train[feature_use] > 0].shape[0] >= 20):\n",
    "                break\n",
    "                \n",
    "        #[TRAIN] - cuts the value of idx from the top of the dataframe; selects the input column (e.g. Number day from 1000 case); brings it into a horizontal array\n",
    "        adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n",
    "        #[TRAIN] - get the respective confirmed cases\n",
    "        adjusted_y_train_confirmed = y_train_confirmed[idx:]\n",
    "        #[TRAIN] - get the respective fatalities\n",
    "        adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n",
    "        \n",
    "        #[TEST] - selects for the extracted feature column and get the length (0)\n",
    "        idx = X_pred[X_pred[feature_use] == 0].shape[0]\n",
    "        \n",
    "        #[TEST] - creates a clean array also for the prediction\n",
    "        adjusted_X_pred = X_pred[idx:][feature_use].values.reshape(-1, 1)\n",
    "        \n",
    "        #[TEST] - gets the extract from the test dataset for a specific country/ region\n",
    "        pred_data = test[(test['Country_Rion'] == country) & (test['Province_State'] == province)]\n",
    "        \n",
    "        #latest date from the trainings data set and earliest date from the test data set\n",
    "        max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n",
    "        min_test_date = pred_data['Date'].min()\n",
    "        \n",
    "        if len(adjusted_y_train_confirmed) < 1:\n",
    "            adjusted_y_train_confirmed = np.zeros(3)\n",
    "        else:\n",
    "            if len(adjusted_y_train_confirmed) < 2:\n",
    "                adjusted_y_train_confirmed = np.append(adjusted_y_train_confirmed,adjusted_y_train_confirmed[len(adjusted_y_train_confirmed)-1],adjusted_y_train_confirmed[len(adjusted_y_train_confirmed)-1])\n",
    "            else:\n",
    "                if len(adjusted_y_train_confirmed) < 3:\n",
    "                    adjusted_y_train_confirmed = np.append(adjusted_y_train_confirmed,adjusted_y_train_confirmed[len(adjusted_y_train_confirmed)-1])\n",
    "                else:\n",
    "                    pass\n",
    "        \n",
    "        #[CONFIRMED CASES] - prediction and modelling\n",
    "        model = SARIMAX(adjusted_y_train_confirmed, order=(1,1,0), \n",
    "                        measurement_error=True).fit(disp=False)\n",
    "        y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n",
    "        y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n",
    "        y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)\n",
    "\n",
    "        if len(adjusted_y_train_fatalities) < 1:\n",
    "            adjusted_y_train_fatalities = np.zeros(3)\n",
    "        else:\n",
    "            if len(adjusted_y_train_fatalities) < 2:\n",
    "                adjusted_y_train_fatalities = np.append(adjusted_y_train_fatalities,adjusted_y_train_fatalities[len(adjusted_y_train_fatalities)-1],adjusted_y_train_fatalities[len(adjusted_y_train_fatalities)-1])\n",
    "            else:\n",
    "                if len(adjusted_y_train_fatalities) < 3:\n",
    "                    adjusted_y_train_fatalities = np.append(adjusted_y_train_fatalities,adjusted_y_train_fatalities[len(adjusted_y_train_fatalities)-1])\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "        #[FATALITIES] - prediction and modelling\n",
    "        model = SARIMAX(adjusted_y_train_fatalities, order=(1,1,0), \n",
    "                        measurement_error=True).fit(disp=False)\n",
    "        y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n",
    "        y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n",
    "        y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)\n",
    "        pred_data['ConfirmedCases_hat'] =  y_hat_confirmed\n",
    "        pred_data['Fatalities_hat'] = y_hat_fatalities\n",
    "        pred_data_all = pred_data_all.append(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
